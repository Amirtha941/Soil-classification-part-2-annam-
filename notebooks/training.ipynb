{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## üì¶ Import Libraries\n\n# Importing standard Python libraries\nimport os  # Provides functions to interact with the operating system\nimport pandas as pd  # For data manipulation and analysis\nimport numpy as np  # For numerical operations and working with arrays\nfrom PIL import Image  # For image loading and preprocessing\n\n# PyTorch libraries for deep learning\nimport torch  # Core PyTorch functionality\nfrom torch.utils.data import Dataset, DataLoader  # For dataset management and batch loading\nimport torch.nn as nn  # For building neural network layers\nimport torch.optim as optim  # For optimization algorithms like SGD, Adam, etc.\n\n# TorchVision libraries for pretrained models and image transformations\nfrom torchvision import transforms, models  # `transforms` for image preprocessing, `models` for pretrained CNNs\n\n# Scikit-learn for preprocessing and evaluation\nfrom sklearn.model_selection import train_test_split  # For splitting the dataset into train and validation sets\nfrom sklearn.preprocessing import LabelEncoder  # For converting class labels to integers\nfrom sklearn.metrics import f1_score  # F1 score is the competition metric\n\n# Set random seed for reproducibility\nSEED = 42\ntorch.manual_seed(SEED)  # Set PyTorch seed\nnp.random.seed(SEED)  # Set NumPy seed\n\n# Set device configuration (CPU only in this environment)\nDEVICE = torch.device('cpu')  # Use 'cuda' if GPU is available\n\n# Set the data directory path\nDATA_DIR = '/kaggle/input/soil-classification-part-2/soil_competition-2025'  # Root directory for dataset\n\nprint(\"Setup done.\")  # Confirm environment is initialized\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.196151Z","iopub.execute_input":"2025-05-24T11:32:06.196720Z","iopub.status.idle":"2025-05-24T11:32:06.210843Z","shell.execute_reply.started":"2025-05-24T11:32:06.196692Z","shell.execute_reply":"2025-05-24T11:32:06.209706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## ‚öôÔ∏è Configuration\n\n# CELL 2: Load data and fix labels to zero-based indexing\n\n# Load the training labels CSV into a pandas DataFrame\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, 'train_labels.csv'))\n\n# Display the original labels to verify their distribution and indexing\nprint(\"Original labels:\", train_df['label'].unique())\n\n# Use LabelEncoder to convert categorical labels into integer labels starting from 0\n# This ensures labels are continuous integers, which is required for PyTorch classification\nle = LabelEncoder()\ntrain_df['label'] = le.fit_transform(train_df['label'])\n\n# Get the number of unique classes after encoding\nNUM_CLASSES = train_df['label'].nunique()\nprint(f\"Number of classes after label encoding: {NUM_CLASSES}\")\n\n# Display the transformed labels to verify successful encoding\nprint(\"Labels after encoding:\", train_df['label'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.212550Z","iopub.execute_input":"2025-05-24T11:32:06.213406Z","iopub.status.idle":"2025-05-24T11:32:06.245641Z","shell.execute_reply.started":"2025-05-24T11:32:06.213381Z","shell.execute_reply":"2025-05-24T11:32:06.244664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 3: Custom Dataset class for loading soil images and labels with transforms\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport os\n\nclass SoilDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): DataFrame containing 'image_id' and 'label' columns\n            root_dir (str): Directory where images are stored\n            transform (callable, optional): Optional torchvision transforms to apply to images\n        \"\"\"\n        self.df = df.reset_index(drop=True)  # Reset index for safe integer indexing\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        # Returns total number of samples in the dataset\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Args:\n            idx (int): Index of the sample to retrieve\n\n        Returns:\n            image (Tensor): Transformed image tensor\n            label (Tensor): Corresponding label as a LongTensor (required for loss functions like CrossEntropyLoss)\n        \"\"\"\n        # Get the image filename using index\n        img_name = self.df.loc[idx, 'image_id']\n        # Get the label for this image\n        label = self.df.loc[idx, 'label']\n\n        # Construct full image path\n        img_path = os.path.join(self.root_dir, img_name)\n\n        # Load the image and convert to RGB (to ensure 3 channels)\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply image transformations if provided (e.g., resize, normalize, augmentations)\n        if self.transform:\n            image = self.transform(image)\n\n        # Convert label to a torch LongTensor for compatibility with classification loss\n        label = torch.tensor(label).long()\n\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.246560Z","iopub.execute_input":"2025-05-24T11:32:06.246797Z","iopub.status.idle":"2025-05-24T11:32:06.254933Z","shell.execute_reply.started":"2025-05-24T11:32:06.246779Z","shell.execute_reply":"2025-05-24T11:32:06.253872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 4: Define data transformations and create train-validation split with DataLoaders\n\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\n\n# Define training data augmentation and preprocessing pipeline\ntransform_train = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize all images to 224x224 (standard input size for many CNNs)\n    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally (data augmentation)\n    transforms.RandomVerticalFlip(),  # Randomly flip images vertically (data augmentation)\n    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor and scale pixel values [0,1]\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet mean and std for pretrained models\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Validation transformations: only resize and normalization (no augmentation)\ntransform_val = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Split dataset into training and validation sets using stratified split to maintain label distribution\ntrain_data, val_data = train_test_split(\n    train_df, \n    test_size=0.2,  # 20% validation split\n    stratify=train_df['label'],  # Maintain class proportions in both sets\n    random_state=SEED  # Reproducible split\n)\n\n# Create PyTorch Dataset objects for train and validation sets\ntrain_dataset = SoilDataset(train_data, os.path.join(DATA_DIR, 'train'), transform=transform_train)\nval_dataset = SoilDataset(val_data, os.path.join(DATA_DIR, 'train'), transform=transform_val)\n\n# Create DataLoaders for batch processing and shuffling during training\ntrain_loader = DataLoader(\n    train_dataset, batch_size=32, shuffle=True, num_workers=2\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=32, shuffle=False, num_workers=2\n)\n\n# Print dataset sizes to verify split\nprint(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.256085Z","iopub.execute_input":"2025-05-24T11:32:06.256422Z","iopub.status.idle":"2025-05-24T11:32:06.291254Z","shell.execute_reply.started":"2025-05-24T11:32:06.256392Z","shell.execute_reply":"2025-05-24T11:32:06.290206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 5: Define model architecture without pretrained weights\n\nfrom torchvision import models\nimport torch.nn as nn\n\n# Initialize a ResNet18 model without pretrained weights to avoid download issues on Kaggle\nmodel = models.resnet18(weights=None)\n\n# Replace the final fully connected layer to match the number of classes in our dataset\n# model.fc.in_features gives the input features to the last layer\nmodel.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n\n# Move the model to the specified device (CPU here, GPU if available)\nmodel = model.to(DEVICE)\n\nprint(\"Model created.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.293440Z","iopub.execute_input":"2025-05-24T11:32:06.294092Z","iopub.status.idle":"2025-05-24T11:32:06.541518Z","shell.execute_reply.started":"2025-05-24T11:32:06.294066Z","shell.execute_reply":"2025-05-24T11:32:06.540608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 6: Define loss function, optimizer, and evaluation metric\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\n\n# CrossEntropyLoss is standard for multi-class classification problems\ncriterion = nn.CrossEntropyLoss()\n\n# Adam optimizer with a learning rate of 0.001 for efficient gradient updates\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndef calculate_min_f1(y_true, y_pred):\n    \"\"\"\n    Calculate the minimum F1 score across all classes.\n    This is the competition evaluation metric, ensuring balanced performance.\n\n    Args:\n        y_true (array-like): Ground truth labels\n        y_pred (array-like): Predicted labels\n\n    Returns:\n        float: Minimum class-wise F1 score\n    \"\"\"\n    # Compute F1 score for each class separately (average=None)\n    f1_scores = f1_score(y_true, y_pred, average=None)\n    # Return the smallest F1 score to capture the worst-performing class\n    return f1_scores.min()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.543074Z","iopub.execute_input":"2025-05-24T11:32:06.543396Z","iopub.status.idle":"2025-05-24T11:32:06.553539Z","shell.execute_reply.started":"2025-05-24T11:32:06.543368Z","shell.execute_reply":"2025-05-24T11:32:06.552724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 7: Training loop with validation and minimum F1 evaluation\n\ndef train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n    \"\"\"\n    Train the model and evaluate on validation set each epoch.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        criterion (loss): Loss function (e.g., CrossEntropyLoss)\n        optimizer (optim): Optimizer (e.g., Adam)\n        train_loader (DataLoader): DataLoader for training data\n        val_loader (DataLoader): DataLoader for validation data\n        epochs (int): Number of training epochs\n\n    Prints:\n        Epoch number, average training loss, and minimum validation F1 score per epoch\n    \"\"\"\n    for epoch in range(epochs):\n        model.train()  # Set model to training mode (enables dropout, batchnorm, etc.)\n\n        running_loss = 0.0  # Accumulate batch losses to compute average per epoch\n\n        for images, labels in train_loader:\n            # Move data to the computation device (CPU/GPU)\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n            optimizer.zero_grad()  # Clear gradients from previous step\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            loss.backward()  # Backpropagation\n            optimizer.step()  # Update weights\n\n            running_loss += loss.item()  # Accumulate loss for monitoring\n\n        avg_loss = running_loss / len(train_loader)  # Average loss for this epoch\n\n        # Validation phase - no gradient computation for efficiency\n        model.eval()  # Set model to evaluation mode (disables dropout, batchnorm updates)\n\n        all_preds = []  # Store predictions for all validation samples\n        all_labels = []  # Store true labels for validation samples\n\n        with torch.no_grad():  # Disable gradient tracking during validation\n            for images, labels in val_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                _, preds = torch.max(outputs, 1)  # Get predicted class indices\n\n                # Move predictions and labels to CPU and convert to numpy for metric calculation\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n\n        # Calculate minimum F1 score across all classes on validation set\n        min_f1 = calculate_min_f1(all_labels, all_preds)\n\n        # Print training stats for the current epoch\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Min F1: {min_f1:.4f}\")\n\n# Start training for 10 epochs\ntrain_model(model, criterion, optimizer, train_loader, val_loader, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:32:06.554586Z","iopub.execute_input":"2025-05-24T11:32:06.554957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load test images using a custom Dataset\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os\n\nclass TestDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        \"\"\"\n        Args:\n            image_dir (str): Path to directory containing test images\n            transform (callable, optional): Transformations to apply to each image\n        \"\"\"\n        self.image_dir = image_dir\n        self.image_ids = sorted(os.listdir(image_dir))  # Ensure consistent ordering\n        self.transform = transform\n\n    def __len__(self):\n        # Return the number of test images\n        return len(self.image_ids)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Args:\n            idx (int): Index of the image to retrieve\n\n        Returns:\n            image (Tensor): Transformed image tensor\n            img_id (str): Corresponding image file name\n        \"\"\"\n        img_id = self.image_ids[idx]  # Get image file name\n        img_path = os.path.join(self.image_dir, img_id)  # Full path to the image\n        image = Image.open(img_path).convert('RGB')  # Ensure image has 3 channels (RGB)\n\n        # Apply transforms if defined (e.g., resize, normalize)\n        if self.transform:\n            image = self.transform(image)\n\n        return image, img_id\n\n# Initialize the test dataset using validation transforms (no augmentation)\ntest_dataset = TestDataset(os.path.join(DATA_DIR, 'test'), transform=transform_val)\n\n# Use DataLoader for efficient batch processing (no shuffling for test set)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Predict on test data using trained model\n\nmodel.eval()  # Set model to evaluation mode (important for inference consistency)\ntest_preds = []   # Store predicted label indices\nimage_ids = []    # Store corresponding image filenames\n\n# Disable gradient computation to speed up inference and reduce memory usage\nwith torch.no_grad():\n    for images, ids in test_loader:\n        images = images.to(DEVICE)  # Move batch to CPU/GPU\n        outputs = model(images)  # Forward pass\n        _, preds = torch.max(outputs, 1)  # Get class index with highest score\n        test_preds.extend(preds.cpu().numpy())  # Move predictions to CPU and store\n        image_ids.extend(ids)  # Save image filenames in original order\n\n# Convert predicted label indices back to original label names using inverse transform\npred_labels = le.inverse_transform(test_preds)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Prepare submission CSV file\n\nimport pandas as pd\n\n# Create a DataFrame with image IDs and corresponding predicted labels\nsubmission_df = pd.DataFrame({\n    'image_id': image_ids,  # Filenames of test images\n    'label': pred_labels    # Predicted string labels (after inverse transform)\n})\n\n# Save the DataFrame to a CSV file in the required format for submission\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved as /kaggle/working/submission.csv\")\n\n\n# Display the first few rows of the submission file for verification\nsubmission_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}